# -*- coding: utf-8 -*-
"""Untitled7.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JpfYNiHsji2kxbUCdUjoKCZG9PT9wsaP
"""

"""
advanced_time_series_attention.py

Advanced multivariate time-series forecasting example:
- Baseline: simple LSTM regressor
- Attention model: LSTM Encoder-Decoder with Bahdanau attention
- Metrics: RMSE, MAE, MAPE
- Attention visualization

Requirements:
pip install torch torchvision torchaudio numpy pandas scikit-learn matplotlib

Usage:
- Edit DATA_CSV_PATH to point to your CSV OR leave None to use synthetic data.
- Run the script.
"""

import os
import math
import random
import numpy as np
import pandas as pd
from typing import Tuple
import matplotlib.pyplot as plt

import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

# ---------------------------
# Path to user-uploaded screenshots (kept as references)
# ---------------------------
# Note: Developer supplied image files (for reference)
SCREENSHOT1 = "/mnt/data/Screenshot 2025-11-22 172058.png"
SCREENSHOT2 = "/mnt/data/Screenshot 2025-11-22 172054.png"

# ---------------------------
# User dataset settings (edit if you have your own CSV)
# ---------------------------
DATA_CSV_PATH = None  # e.g. "/path/to/your/multivariate.csv". If None => synthetic data generated.
TARGET_COL = None     # If None, we'll forecast the first column of features.
TEST_SIZE = 0.15
VAL_SIZE = 0.15

# Sequence / forecasting settings
INPUT_WINDOW = 48   # number of past timesteps used as input
OUTPUT_WINDOW = 12  # number of timesteps to predict
BATCH_SIZE = 64
NUM_FEATURES_MIN = 5  # ensure at least 5 features for the assignment requirement
RANDOM_SEED = 42
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Using device:", DEVICE)

# Training hyperparams
EPOCHS = 30
LR = 1e-3
HIDDEN_SIZE = 128
NUM_LAYERS = 1
DROPOUT = 0.1

torch.manual_seed(RANDOM_SEED)
np.random.seed(RANDOM_SEED)
random.seed(RANDOM_SEED)

# ---------------------------
# Utility: metrics
# ---------------------------
def rmse(y_true, y_pred):
    return np.sqrt(np.mean((y_true - y_pred) ** 2))

def mae(y_true, y_pred):
    return np.mean(np.abs(y_true - y_pred))

def mape(y_true, y_pred):
    denom = np.where(np.abs(y_true) < 1e-6, 1e-6, np.abs(y_true))
    return np.mean(np.abs((y_true - y_pred) / denom)) * 100.0

# ---------------------------
# Data preparation
# ---------------------------
def generate_synthetic_multivariate(n_samples=5000, n_features=6):
    """Generates synthetic multivariate time series with correlated signals."""
    t = np.arange(n_samples)
    data = []
    # base signals
    s1 = np.sin(2 * math.pi * t / 50)  # seasonal
    s2 = np.cos(2 * math.pi * t / 80)  # seasonal
    s3 = np.sin(2 * math.pi * t / 12) * 0.2  # faster seasonality
    for i in range(n_features):
        noise = np.random.normal(scale=0.3, size=n_samples)
        weight1 = 1.0 + 0.1 * i
        weight2 = 0.5 + 0.05 * i
        series = weight1 * s1 + weight2 * s2 + s3 * (0.5 + 0.1 * i) + noise
        # slowly drifting trend
        series += 0.001 * t * (i+1)
        data.append(series)
    df = pd.DataFrame(np.stack(data, axis=1), columns=[f"f{i}" for i in range(n_features)])
    return df

def load_dataset(path: str = None) -> pd.DataFrame:
    if path is None:
        print("No CSV provided â€” generating synthetic data.")
        df = generate_synthetic_multivariate(n_samples=6000, n_features=max(NUM_FEATURES_MIN, 6))
    else:
        print(f"Loading CSV from {path}")
        df = pd.read_csv(path)
        # If there's a datetime column, we won't rely on it here; just numeric features
        # Keep only numeric columns
        df = df.select_dtypes(include=[np.number])
        if df.shape[1] < NUM_FEATURES_MIN:
            raise ValueError(f"Dataset must have at least {NUM_FEATURES_MIN} numeric features.")
    return df

def create_sequences(values: np.ndarray, input_window: int, output_window: int) -> Tuple[np.ndarray, np.ndarray]:
    X = []
    Y = []
    L = len(values)
    step = 1
    for start in range(0, L - input_window - output_window + 1, step):
        end = start + input_window
        out_end = end + output_window
        X.append(values[start:end])
        Y.append(values[end:out_end])
    return np.array(X), np.array(Y)

class TimeSeriesDataset(Dataset):
    def __init__(self, X, Y):
        # X: (N, input_window, num_features)
        # Y: (N, output_window, num_targets)
        self.X = torch.tensor(X, dtype=torch.float32)
        self.Y = torch.tensor(Y, dtype=torch.float32)

    def __len__(self):
        return len(self.X)

    def __getitem__(self, idx):
        return self.X[idx], self.Y[idx]

# ---------------------------
# Models
# ---------------------------
class BaselineLSTM(nn.Module):
    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout=0.0):
        super().__init__()
        self.lstm = nn.LSTM(input_size, hidden_size, num_layers=num_layers,
                            batch_first=True, dropout=dropout)
        self.fc = nn.Linear(hidden_size, output_size)

    def forward(self, x):
        # x: (batch, seq_len, input_size)
        out, (h, c) = self.lstm(x)  # out: (batch, seq_len, hidden)
        # use last hidden for prediction of each future step in a naive autoregressive manner:
        # We'll produce OUTPUT_WINDOW steps by repeating a simple forecast head using last hidden.
        last_hidden = out[:, -1, :]  # (batch, hidden)
        # Predict next OUTPUT_WINDOW * output_size values and reshape
        # But simpler: predict the entire sequence in one shot by mapping last_hidden -> output_window x output_size
        # So output_size passed is output_window * num_targets
        y = self.fc(last_hidden)
        return y

# Bahdanau attention components for seq2seq
class Encoder(nn.Module):
    def __init__(self, input_size, hidden_size, num_layers=1, dropout=0.0):
        super().__init__()
        self.lstm = nn.LSTM(input_size, hidden_size, num_layers=num_layers,
                            batch_first=True, bidirectional=False, dropout=dropout)

    def forward(self, x):
        # x: (batch, seq_len, input_size)
        outputs, (h_n, c_n) = self.lstm(x)
        # outputs: (batch, seq_len, hidden)
        return outputs, (h_n, c_n)

class BahdanauAttention(nn.Module):
    def __init__(self, hidden_size, attn_size=None):
        super().__init__()
        if attn_size is None:
            attn_size = hidden_size
        self.W_enc = nn.Linear(hidden_size, attn_size, bias=False)
        self.W_dec = nn.Linear(hidden_size, attn_size, bias=False)
        self.v = nn.Linear(attn_size, 1, bias=False)

    def forward(self, encoder_outputs, decoder_hidden):
        # encoder_outputs: (batch, seq_len, hidden)
        # decoder_hidden: (batch, hidden)  -> current decoder hidden state
        # Compute score for each encoder timestep
        # e_t = v^T * tanh(W_enc * enc_out + W_dec * dec_hidden)
        # expand dec_hidden to seq_len
        enc_proj = self.W_enc(encoder_outputs)  # (batch, seq_len, attn_size)
        dec_proj = self.W_dec(decoder_hidden).unsqueeze(1)  # (batch, 1, attn_size)
        energy = torch.tanh(enc_proj + dec_proj)  # broadcast
        scores = self.v(energy).squeeze(-1)  # (batch, seq_len)
        attn_weights = torch.softmax(scores, dim=1)  # (batch, seq_len)
        # context vector
        context = torch.bmm(attn_weights.unsqueeze(1), encoder_outputs).squeeze(1)  # (batch, hidden)
        return context, attn_weights

class DecoderWithAttention(nn.Module):
    def __init__(self, input_size, hidden_size, output_size, attn_module, num_layers=1, dropout=0.0):
        super().__init__()
        self.hidden_size = hidden_size
        self.attn = attn_module
        # input to decoder at each step will be previous target (or initial token)
        self.lstm_cell = nn.LSTMCell(input_size + hidden_size, hidden_size)
        self.fc_out = nn.Linear(hidden_size, output_size)

    def forward(self, encoder_outputs, decoder_inputs=None, teacher_forcing_ratio=0.5):
        # encoder_outputs: (batch, enc_seq_len, hidden)
        # decoder_inputs: (batch, dec_seq_len, input_size) -> for teacher forcing (optional)
        batch = encoder_outputs.size(0)
        dec_seq_len = decoder_inputs.size(1) if (decoder_inputs is not None) else OUTPUT_WINDOW
        device = encoder_outputs.device

        # initialize decoder hidden state (zeros)
        h = torch.zeros(batch, self.hidden_size, device=device)
        c = torch.zeros(batch, self.hidden_size, device=device)

        # use last timestep's encoder output as initial input (or zeros)
        # We'll set first decoder input as zeros
        input_step = torch.zeros(batch, decoder_inputs.size(2) if decoder_inputs is not None else encoder_outputs.size(2), device=device)

        outputs = []
        attn_weights_all = []

        for t in range(dec_seq_len):
            # compute attention context using current hidden state
            context, attn_weights = self.attn(encoder_outputs, h)  # context: (batch, hidden)
            attn_weights_all.append(attn_weights.detach().cpu().numpy())
            # combine input_step and context
            lstm_input = torch.cat([input_step, context], dim=1)  # (batch, input_size + hidden)
            h, c = self.lstm_cell(lstm_input, (h, c))
            out_step = self.fc_out(h)  # predict one-step output (target vector)
            outputs.append(out_step.unsqueeze(1))
            # next input: teacher forcing or use own prediction
            if decoder_inputs is not None and (np.random.rand() < teacher_forcing_ratio):
                input_step = decoder_inputs[:, t, :]
            else:
                input_step = out_step  # use predicted as next input

        outputs = torch.cat(outputs, dim=1)  # (batch, dec_seq_len, out_size)
        attn_weights_all = np.stack(attn_weights_all, axis=1)  # (batch, dec_seq_len, enc_seq_len)
        return outputs, attn_weights_all

class Seq2SeqAttention(nn.Module):
    def __init__(self, input_size, hidden_size, output_size, num_layers=1, dropout=0.0):
        super().__init__()
        self.encoder = Encoder(input_size, hidden_size, num_layers=num_layers, dropout=dropout)
        attn = BahdanauAttention(hidden_size)
        self.decoder = DecoderWithAttention(input_size=input_size, hidden_size=hidden_size,
                                            output_size=output_size, attn_module=attn,
                                            num_layers=num_layers, dropout=dropout)

    def forward(self, src, trg=None, teacher_forcing_ratio=0.5):
        # src: (batch, src_seq_len, input_size)
        encoder_outputs, (h_n, c_n) = self.encoder(src)
        outputs, attn_weights_all = self.decoder(encoder_outputs, decoder_inputs=trg, teacher_forcing_ratio=teacher_forcing_ratio)
        return outputs, attn_weights_all

# ---------------------------
# Training and evaluation functions
# ---------------------------
def train_epoch_baseline(model, loader, criterion, optimizer, device):
    model.train()
    total_loss = 0.0
    for xb, yb in loader:
        xb = xb.to(device)
        yb = yb.to(device)
        optimizer.zero_grad()
        # baseline's forward returns flattened predictions: size (batch, output_window * num_targets)
        preds = model(xb)
        # reshape yb to match predictions
        # yb: (batch, out_len, num_targets)
        batch, out_len, num_targets = yb.size()
        preds = preds.view(batch, out_len, num_targets)
        loss = criterion(preds, yb)
        loss.backward()
        optimizer.step()
        total_loss += loss.item() * xb.size(0)
    return total_loss / len(loader.dataset)

def eval_baseline(model, loader, device):
    model.eval()
    preds_list = []
    trues_list = []
    with torch.no_grad():
        for xb, yb in loader:
            xb = xb.to(device)
            yb = yb.to(device)
            preds = model(xb)
            batch, out_len, num_targets = yb.size()
            preds = preds.view(batch, out_len, num_targets)
            preds_list.append(preds.cpu().numpy())
            trues_list.append(yb.cpu().numpy())
    pred = np.concatenate(preds_list, axis=0)
    true = np.concatenate(trues_list, axis=0)
    return true, pred

def train_epoch_seq2seq(model, loader, criterion, optimizer, device, teacher_forcing_ratio=0.5):
    model.train()
    total_loss = 0.0
    for xb, yb in loader:
        xb = xb.to(device)
        yb = yb.to(device)
        optimizer.zero_grad()
        preds, _ = model(xb, trg=yb, teacher_forcing_ratio=teacher_forcing_ratio)
        loss = criterion(preds, yb)
        loss.backward()
        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
        optimizer.step()
        total_loss += loss.item() * xb.size(0)
    return total_loss / len(loader.dataset)

def eval_seq2seq(model, loader, device):
    model.eval()
    preds_list = []
    trues_list = []
    attn_collect = []  # collect attention weights for first batch
    with torch.no_grad():
        for i, (xb, yb) in enumerate(loader):
            xb = xb.to(device)
            yb = yb.to(device)
            preds, attn_weights = model(xb, trg=None, teacher_forcing_ratio=0.0)  # no teacher forcing during eval
            preds_list.append(preds.cpu().numpy())
            trues_list.append(yb.cpu().numpy())
            if i == 0:
                attn_collect = attn_weights  # shape (batch, dec_seq_len, enc_seq_len)
    pred = np.concatenate(preds_list, axis=0)
    true = np.concatenate(trues_list, axis=0)
    return true, pred, attn_collect

# ---------------------------
# Run full experiment pipeline
# ---------------------------
def run_pipeline():
    # 1) Load data
    df = load_dataset(DATA_CSV_PATH)
    print("Data shape:", df.shape)
    values = df.values.astype(np.float32)

    # 2) choose target(s)
    n_features = values.shape[1]
    target_idx = 0 if TARGET_COL is None else df.columns.get_loc(TARGET_COL)
    # We'll forecast all features by default (multi-output). If you want single target, slice accordingly.
    num_targets = n_features
    print("Num features:", n_features, "Num targets:", num_targets)

    # 3) scale features (fit on train-only later; for simplicity we will split first then scale)
    # Create sequences first, then split to avoid leakage? Better: split indices in time order
    # We'll create sequences from the full series, then split by time (train/val/test contiguous).
    X_all, Y_all = create_sequences(values, INPUT_WINDOW, OUTPUT_WINDOW)
    # X_all shape: (N, INPUT_WINDOW, n_features)
    # Y_all shape: (N, OUTPUT_WINDOW, n_features)
    N = X_all.shape[0]
    test_split = int(N * (1 - TEST_SIZE))
    val_split = int(test_split * (1 - VAL_SIZE / (1 - TEST_SIZE)))  # keep relative sizes

    X_train = X_all[:val_split]
    Y_train = Y_all[:val_split]
    X_val = X_all[val_split:test_split]
    Y_val = Y_all[val_split:test_split]
    X_test = X_all[test_split:]
    Y_test = Y_all[test_split:]

    print("Train/Val/Test sizes:", len(X_train), len(X_val), len(X_test))

    # Fit scaler on training data only
    scaler = StandardScaler()
    # reshape train to (num_samples * seq_len, n_features)
    scaler.fit(X_train.reshape(-1, n_features))
    # transform all splits
    def scale_split(X):
        b, s, f = X.shape
        Xs = scaler.transform(X.reshape(-1, f)).reshape(b, s, f)
        return Xs
    def scale_targets(Y):
        b, s, f = Y.shape
        Ys = scaler.transform(Y.reshape(-1, f)).reshape(b, s, f)
        return Ys

    X_train_s = scale_split(X_train)
    X_val_s = scale_split(X_val)
    X_test_s = scale_split(X_test)
    Y_train_s = scale_targets(Y_train)
    Y_val_s = scale_targets(Y_val)
    Y_test_s = scale_targets(Y_test)

    # Datasets and loaders
    train_ds = TimeSeriesDataset(X_train_s, Y_train_s)
    val_ds = TimeSeriesDataset(X_val_s, Y_val_s)
    test_ds = TimeSeriesDataset(X_test_s, Y_test_s)
    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)
    test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)

    # ---------------------------
    # Baseline model (simple LSTM)
    # ---------------------------
    print("\n--- Training baseline LSTM ---")
    baseline_output_size = OUTPUT_WINDOW * num_targets  # fc maps last hidden to this flattened size
    baseline = BaselineLSTM(input_size=n_features, hidden_size=HIDDEN_SIZE, num_layers=NUM_LAYERS,
                            output_size=baseline_output_size, dropout=DROPOUT).to(DEVICE)
    criterion = nn.MSELoss()
    optimizer = torch.optim.Adam(baseline.parameters(), lr=LR)

    best_val_loss = 1e9
    baseline_hist = {"train_loss": [], "val_loss": []}
    for epoch in range(1, EPOCHS + 1):
        train_loss = train_epoch_baseline(baseline, train_loader, criterion, optimizer, DEVICE)
        baseline_hist["train_loss"].append(train_loss)
        # eval val
        baseline.eval()
        val_true, val_pred = eval_baseline(baseline, val_loader, DEVICE)
        val_loss = criterion(torch.tensor(val_pred), torch.tensor(val_true)).item()
        baseline_hist["val_loss"].append(val_loss)
        print(f"Epoch {epoch}/{EPOCHS} | train_loss: {train_loss:.6f} | val_loss: {val_loss:.6f}")
        if val_loss < best_val_loss:
            best_val_loss = val_loss
            torch.save(baseline.state_dict(), "best_baseline.pth")

    # Evaluate baseline on test set
    true_test, pred_test = eval_baseline(baseline, test_loader, DEVICE)
    # inverse scale
    def inv_scale(arr):
        b, s, f = arr.shape
        return scaler.inverse_transform(arr.reshape(-1, f)).reshape(b, s, f)
    true_test_un = inv_scale(true_test)
    pred_test_un = inv_scale(pred_test)
    # compute metrics (flatten across timesteps and features)
    true_flat = true_test_un.reshape(-1, num_targets)
    pred_flat = pred_test_un.reshape(-1, num_targets)

    baseline_metrics = {
        "RMSE": rmse(true_flat, pred_flat),
        "MAE": mae(true_flat, pred_flat),
        "MAPE": mape(true_flat, pred_flat)
    }
    print("\nBaseline test metrics:", baseline_metrics)

    # ---------------------------
    # Attention seq2seq model
    # ---------------------------
    print("\n--- Training Seq2Seq with Attention ---")
    seq2seq = Seq2SeqAttention(input_size=n_features, hidden_size=HIDDEN_SIZE,
                               output_size=num_targets, num_layers=NUM_LAYERS, dropout=DROPOUT).to(DEVICE)
    optimizer2 = torch.optim.Adam(seq2seq.parameters(), lr=LR)
    best_val_loss2 = 1e9
    seq_hist = {"train_loss": [], "val_loss": []}

    for epoch in range(1, EPOCHS + 1):
        train_loss = train_epoch_seq2seq(seq2seq, train_loader, criterion, optimizer2, DEVICE, teacher_forcing_ratio=0.7)
        seq_hist["train_loss"].append(train_loss)
        # evaluate on val
        seq2seq.eval()
        val_true, val_pred, _ = eval_seq2seq(seq2seq, val_loader, DEVICE)
        val_loss = criterion(torch.tensor(val_pred), torch.tensor(val_true)).item()
        seq_hist["val_loss"].append(val_loss)
        print(f"Epoch {epoch}/{EPOCHS} | train_loss: {train_loss:.6f} | val_loss: {val_loss:.6f}")
        if val_loss < best_val_loss2:
            best_val_loss2 = val_loss
            torch.save(seq2seq.state_dict(), "best_seq2seq_attn.pth")

    # Evaluate seq2seq on test set
    seq_true_test, seq_pred_test, attn_weights = eval_seq2seq(seq2seq, test_loader, DEVICE)
    seq_true_un = inv_scale(seq_true_test)
    seq_pred_un = inv_scale(seq_pred_test)

    seq_flat_true = seq_true_un.reshape(-1, num_targets)
    seq_flat_pred = seq_pred_un.reshape(-1, num_targets)

    seq_metrics = {
        "RMSE": rmse(seq_flat_true, seq_flat_pred),
        "MAE": mae(seq_flat_true, seq_flat_pred),
        "MAPE": mape(seq_flat_true, seq_flat_pred)
    }
    print("\nSeq2Seq+Attention test metrics:", seq_metrics)

    # ---------------------------
    # Plot training curves
    # ---------------------------
    plt.figure(figsize=(8,4))
    plt.plot(baseline_hist["train_loss"], label="baseline train")
    plt.plot(baseline_hist["val_loss"], label="baseline val")
    plt.plot(seq_hist["train_loss"], label="seq2seq train")
    plt.plot(seq_hist["val_loss"], label="seq2seq val")
    plt.yscale('log')
    plt.title("Training curves (MSE)")
    plt.legend()
    plt.tight_layout()
    plt.savefig("training_curves.png")
    print("Saved training curves to training_curves.png")

    # ---------------------------
    # Attention visualization
    # ---------------------------
    # attn_weights shape (batch, dec_seq_len, enc_seq_len) for first test batch captured earlier
    if isinstance(attn_weights, np.ndarray) and attn_weights.size > 0:
        # visualize attention for first example in batch
        attn_example = attn_weights[0]  # (dec_seq_len, enc_seq_len)
        plt.figure(figsize=(10, 6))
        plt.imshow(attn_example, aspect='auto', origin='lower')
        plt.colorbar()
        plt.xlabel("Encoder time step")
        plt.ylabel("Decoder time step (forecast horizon)")
        plt.title("Attention weights (example)")
        plt.tight_layout()
        plt.savefig("attention_heatmap.png")
        print("Saved attention heatmap to attention_heatmap.png")
    else:
        print("No attention weights to visualize.")

    # ---------------------------
    # Save summary metrics
    # ---------------------------
    summary = {
        "baseline_metrics": baseline_metrics,
        "seq2seq_metrics": seq_metrics
    }
    pd.DataFrame(summary).to_csv("metrics_summary.csv")
    print("Saved metrics_summary.csv")

    # Print comparative summary
    print("\n--- Comparative Summary ---")
    print("Baseline:", baseline_metrics)
    print("Attention model:", seq_metrics)
    print("\nOutputs saved in current directory: best_baseline.pth, best_seq2seq_attn.pth, training_curves.png, attention_heatmap.png, metrics_summary.csv")